<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MATH3823 Generalised Linear Models - 4&nbsp; GLM Estimation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./5_logisticmodel.html" rel="next">
<link href="./3_GLM-Theory.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="webex.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./4_GLM-Fitting.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">GLM Estimation</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">MATH3823 Generalised Linear Models</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Weekly schedule</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./0_preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2_linearmodels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Essentials of Normal Linear Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3_GLM-Theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GLM Theory</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4_GLM-Fitting.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">GLM Estimation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5_logisticmodel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Modelling Proportions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./6_loglinearmodel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Loglinear Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./7_extendedloglinearmodel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Extensions to Loglinear models</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-mleiid" id="toc-sec-mleiid" class="nav-link active" data-scroll-target="#sec-mleiid"><span class="header-section-number">4.1</span> The identically distributed case</a>
  <ul class="collapse">
  <li><a href="#maximum-likelihood-estimation" id="toc-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#maximum-likelihood-estimation"><span class="header-section-number">4.1.1</span> Maximum likelihood estimation</a></li>
  <li><a href="#estimation-accuracy" id="toc-estimation-accuracy" class="nav-link" data-scroll-target="#estimation-accuracy"><span class="header-section-number">4.1.2</span> Estimation accuracy</a></li>
  </ul></li>
  <li><a href="#focus-on-maximum-likelihood-quiz" id="toc-focus-on-maximum-likelihood-quiz" class="nav-link" data-scroll-target="#focus-on-maximum-likelihood-quiz">Focus on maximum likelihood quiz</a></li>
  <li><a href="#sec-mlegeneral" id="toc-sec-mlegeneral" class="nav-link" data-scroll-target="#sec-mlegeneral"><span class="header-section-number">4.2</span> The general case</a>
  <ul class="collapse">
  <li><a href="#mle-estimation" id="toc-mle-estimation" class="nav-link" data-scroll-target="#mle-estimation"><span class="header-section-number">4.2.1</span> MLE Estimation</a></li>
  <li><a href="#sec-score" id="toc-sec-score" class="nav-link" data-scroll-target="#sec-score"><span class="header-section-number">4.2.2</span> The score function and Fisher information</a></li>
  <li><a href="#sec-mlesaturated" id="toc-sec-mlesaturated" class="nav-link" data-scroll-target="#sec-mlesaturated"><span class="header-section-number">4.2.3</span> The saturated case</a></li>
  </ul></li>
  <li><a href="#focus-on-general-maximum-likelihood-quiz" id="toc-focus-on-general-maximum-likelihood-quiz" class="nav-link" data-scroll-target="#focus-on-general-maximum-likelihood-quiz">Focus on general maximum likelihood quiz</a></li>
  <li><a href="#sec-deviance" id="toc-sec-deviance" class="nav-link" data-scroll-target="#sec-deviance"><span class="header-section-number">4.3</span> Model deviance</a></li>
  <li><a href="#model-residuals" id="toc-model-residuals" class="nav-link" data-scroll-target="#model-residuals"><span class="header-section-number">4.4</span> Model residuals</a></li>
  <li><a href="#fitting-generalised-linear-models-in-r" id="toc-fitting-generalised-linear-models-in-r" class="nav-link" data-scroll-target="#fitting-generalised-linear-models-in-r"><span class="header-section-number">4.5</span> Fitting generalised linear models in <strong>R</strong></a>
  <ul class="collapse">
  <li><a href="#glm-related-r-commands" id="toc-glm-related-r-commands" class="nav-link" data-scroll-target="#glm-related-r-commands"><span class="header-section-number">4.5.1</span> GLM-related <strong>R</strong> commands</a></li>
  <li><a href="#example-of-fitting-poisson-glm-in-r" id="toc-example-of-fitting-poisson-glm-in-r" class="nav-link" data-scroll-target="#example-of-fitting-poisson-glm-in-r"><span class="header-section-number">4.5.2</span> Example of fitting Poisson GLM in <strong>R</strong></a></li>
  </ul></li>
  <li><a href="#focus-on-glm-fitting-in-r-quiz" id="toc-focus-on-glm-fitting-in-r-quiz" class="nav-link" data-scroll-target="#focus-on-glm-fitting-in-r-quiz">Focus on GLM fitting in R quiz</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">4.6</span> Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">GLM Estimation</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Throughout this module we use the principle of maximum likelihood estimation (MLE) to estimate model parameters and will consider two cases.</p>
<section id="sec-mleiid" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="sec-mleiid"><span class="header-section-number">4.1</span> The identically distributed case</h2>
<section id="maximum-likelihood-estimation" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="maximum-likelihood-estimation"><span class="header-section-number">4.1.1</span> Maximum likelihood estimation</h3>
<p>Suppose we have <span class="math inline">\(n\)</span> independent and identically distributed (i.i.d.) observations <span class="math inline">\(\mathbf{y} = \{y_i,\ i=1,\dots,n\}\)</span>, where each <span class="math inline">\(y_i\)</span> is sampled from the same exponential family density <span id="eq-iidobs"><span class="math display">\[
f(y_i; \theta,\phi) = \exp \left\{ \frac{y_i\theta  - b(\theta)}{\phi} + c(y_i, \phi) \right\},
\tag{4.1}\]</span></span> for <span class="math inline">\(i=1,\dots,n.\)</span> In this case, the canonical parameter <span class="math inline">\(\theta\)</span> does not depend on <span class="math inline">\(i\)</span> as the observations are identically distributed and hence must have the same parameter.</p>
<p>By independence, the joint distribution of all the observations <span class="math inline">\(\mathbf{y}\)</span> is: <span class="math display">\[
f(\mathbf{y}; \theta,\phi) = \prod_{i=1}^n f(y_i; \theta, \phi).
\]</span> So, taking logs and then substituting for the probability function using the exponential family form, <a href="3_GLM-Theory.html#eq-exponential-family">Equation&nbsp;<span>3.3</span></a>, gives <span class="math display">\[
\log f(\mathbf{y}; \theta,\phi) = \sum_{i=1}^n \log f(y_i; \theta, \phi)
= \sum_{i=1}^n \left[\frac{y_i\theta  - b(\theta)}{\phi} + c(y_i, \phi)\right].
\]</span> Regarding the observations <span class="math inline">\(\mathbf{y}\)</span> as constants (which they are, once we have data) and the scale parameter <span class="math inline">\(\phi\)</span> as a fixed <em>nuisance</em> parameter (whose value we may not know), the log-likelihood as a function of the parameter of interest <span class="math inline">\(\theta\)</span> is: <span id="eq-ltheta"><span class="math display">\[
l(\theta; \mathbf{y},\phi)  = n\left( \frac{\bar{y}\, \theta  -  b(\theta)}{\phi}\right) + \mbox{constant},
\tag{4.2}\]</span></span> where <span class="math inline">\(\bar{y}= \sum y_i/n.\)</span></p>
<p>We estimate <span class="math inline">\(\theta\)</span> by maximizing the log likelihood – i.e.&nbsp;given the data <span class="math inline">\(\mathbf{y}\)</span>, we estimate the value of <span class="math inline">\(\theta\)</span> to be that value for which the likelihood, and hence the log-likelihood, is greatest.</p>
<p>We maximize the log-likelihood by differentiating it and setting it to zero: <span class="math display">\[
\frac{d l(\theta; \mathbf{y},\phi)}{d \theta}  
= n \left(\frac{\bar{y} -  b'(\theta)}{\phi}\right)
\]</span> and hence the MLE for <span class="math inline">\(\theta\)</span>, which we denote <span class="math inline">\(\hat\theta\)</span>, satisfies <span id="eq-exponentialfamilybary"><span class="math display">\[
b'(\hat\theta) = \bar{y}
\tag{4.3}\]</span></span> and hence <span id="eq-exponentialfamilybary2"><span class="math display">\[
\hat\theta =  (b')^{-1}(\bar{y}).
\tag{4.4}\]</span></span></p>
<p>Further, we showed in <a href="3_GLM-Theory.html#prp-moments">Proposition&nbsp;<span>3.1</span></a> that <span class="math inline">\(\mbox{E}[Y] = \mu =b'(\theta)\)</span> and if we let <span class="math inline">\(\hat\mu\)</span> denote the MLE of <span class="math inline">\(\mu\)</span>, then <span class="math inline">\(\hat\mu = b'(\hat{\theta})\)</span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, hence we have <span class="math inline">\(\hat\mu = \bar{y}\)</span>. So we find that <span class="math inline">\(\hat\theta\)</span> is the value of <span class="math inline">\(\theta\)</span> for which the theoretical mean <span class="math inline">\(\hat\mu = b'(\hat\theta)\)</span> matches the sample mean <span class="math inline">\(\bar{y}\)</span>.</p>
<blockquote class="blockquote">
<p><strong>Example: MLE of the Poisson distribution</strong></p>
<p>For the Poisson distribution, <span class="math inline">\(\text{Po}(\lambda)\)</span>, we have found that <span class="math inline">\(b(\theta) = e^\theta\)</span> and therefore <span class="math inline">\(b'(\theta) = e^\theta\)</span>. Hence, the MLE of natural parameter <span class="math inline">\(\theta\)</span> is found as the solution of <span class="math inline">\(b'(\hat\theta) = e^{\hat\theta} = \bar{y}\)</span>, that is <span class="math inline">\(\hat\theta = \log(\bar{y})\)</span>.</p>
</blockquote>
</section>
<section id="estimation-accuracy" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="estimation-accuracy"><span class="header-section-number">4.1.2</span> Estimation accuracy</h3>
<p>For our i.i.d. sample <span class="math inline">\(\mathbf{y} = \{y_i,\ i=1,\dots,n\}\)</span>, we have <span class="math inline">\(b'(\hat\theta) = \hat\mu = \bar y\)</span>. Let <span class="math inline">\(\theta_0\)</span> be the true value of <span class="math inline">\(\theta\)</span> with corresponding mean <span class="math inline">\(\mu_0\)</span>, i.e.&nbsp;<span id="eq-mu0"><span class="math display">\[
b'(\theta_0) = \mu_0.  
\tag{4.5}\]</span></span> How accurate is <span class="math inline">\(\hat\theta\)</span>? We know that <span id="eq-ebary"><span class="math display">\[
\mbox{E}[\bar Y] = \mbox{E}\left[\frac{1}{n}\sum_{i=1}^n Y_i\right]
= \frac{1}{n} \sum_{i=1}^n \mbox{E}[Y_i]
= \mu_0  
= b'(\theta_0),
\tag{4.6}\]</span></span> using <a href="#eq-mu0">Equation&nbsp;<span>4.5</span></a>. Also, <span class="math display">\[
\mbox{Var}[\bar Y] = \mbox{Var}\left[\frac{1}{n} \sum_{i=1}^n Y_i\right]
= \frac{1}{n^2}  \sum_{i=1}^n \mbox{Var}[Y_i]
\]</span> because the observations are independent. Then, using the result <a href="3_GLM-Theory.html#eq-exponential-moments">Equation&nbsp;<span>3.8</span></a> gives <span id="eq-varbary"><span class="math display">\[
\mbox{Var}[\bar Y]= \frac{1}{n} \ b''(\theta_0) \phi.
\tag{4.7}\]</span></span></p>
<p>We can use Taylor’s theorem to expand <span class="math inline">\(b'(\hat\theta)\)</span> about <span class="math inline">\(\theta_0\)</span>: <span class="math display">\[
\bar y = b'(\hat\theta) \approx  b'(\theta_0) + (\hat\theta - \theta_0) b''(\theta_0),
\]</span> which implies that <span id="eq-hatthetatheta0"><span class="math display">\[
(\hat\theta - \theta_0) \approx  b''(\theta_0)^{-1}\{b'(\hat\theta) - b'(\theta_0)\}  
= b''(\theta_0)^{-1}(\bar Y - \mu_0),
\tag{4.8}\]</span></span> using <a href="#eq-exponentialfamilybary">Equation&nbsp;<span>4.3</span></a> and <a href="#eq-mu0">Equation&nbsp;<span>4.5</span></a>. We can use <a href="#eq-hatthetatheta0">Equation&nbsp;<span>4.8</span></a> to get approximations to the mean and variance of <span class="math inline">\(\hat\theta\)</span>: <span class="math display">\[
\mbox{E}[\hat\theta - \theta_0]  \approx   b''(\theta_0)^{-1} \mbox{E}[\bar Y - \mu_0]
= 0,
\]</span> using <a href="#eq-ebary">Equation&nbsp;<span>4.6</span></a>, so <span id="eq-ehattheta"><span class="math display">\[
\mbox{E}[\hat\theta] \approx \theta_0,
\tag{4.9}\]</span></span> and <span class="math display">\[
\mbox{Var}(\hat\theta) \approx \mbox{E}\left[(\hat\theta - \theta_0)^2\right]
\]</span> using <a href="#eq-ehattheta">Equation&nbsp;<span>4.9</span></a>, <span class="math display">\[
\mbox{Var}(\hat\theta) \approx \mbox{E}\left[\left(b''(\theta_0)^{-1}(\bar Y - \mu_0)\right)^2\right]
\]</span> using <a href="#eq-hatthetatheta0">Equation&nbsp;<span>4.8</span></a>, <span class="math display">\[
\mbox{Var}(\hat\theta)\approx  \left(b''(\theta_0)\right)^{-2} \mbox{Var}[\bar Y]  
\]</span> using <a href="#eq-ebary">Equation&nbsp;<span>4.6</span></a>, <span id="eq-varhattheta"><span class="math display">\[
\mbox{Var}(\hat\theta) = \frac{\phi}{n \ b''(\theta_0)}
\tag{4.10}\]</span></span> using <a href="#eq-varbary">Equation&nbsp;<span>4.7</span></a>.</p>
<p>Thus we see that the first two derivatives of <span class="math inline">\(b(\theta)\)</span> play a key role in inference.</p>
<blockquote class="blockquote">
<p><strong>Example: Accuracy for the Poisson distribution</strong></p>
<p>For the Poisson distribution, <span class="math inline">\(\text{Po}(\lambda)\)</span>, we have found that <span class="math inline">\(\hat\theta = \log(\bar{Y})\)</span>. Using <a href="#eq-ehattheta">Equation&nbsp;<span>4.9</span></a> we know that <span class="math inline">\(\hat\theta\)</span> is, at least, approximately unbiased. Then, using that <span class="math inline">\(\phi=1\)</span> (<a href="3_GLM-Theory.html#tbl-glm-poisson">Table&nbsp;<span>3.2</span></a>), <span class="math inline">\(b'(\theta)=e^{\theta}\)</span> (<a href="3_GLM-Theory.html#tbl-canonicalrange">Table&nbsp;<span>3.6</span></a>) hence <span class="math inline">\(b''(\theta)=e^{\theta}\)</span>, and using <a href="#eq-varhattheta">Equation&nbsp;<span>4.10</span></a>, leads to the result <span class="math display">\[
\mbox{Var}(\hat\theta) = \frac{\phi}{n \ b''(\theta_0)}
=
\frac{1}{n e^{\theta_0}}.
\]</span></p>
</blockquote>
</section>
</section>
<section id="focus-on-maximum-likelihood-quiz" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="focus-on-maximum-likelihood-quiz">Focus on maximum likelihood quiz</h2>
<p>Test your knowledge recall and application to reinforce basic ideas and prepare for similar concepts later in the Chapter</p>
<div class="webex-box">
<div class="webex-check">
<ol type="1">
<li><p>Which of the following statements best describes the purpose of maximum likelihood estimation? <select class="webex-select"><option value="blank"></option><option value="">To calculate the mean of a distribution</option><option value="answer">To find good values of unknown model parameters</option><option value="">To summarise a data set</option><option value="">To estimate probabilities of unknown events</option><option value="">To find the true values of model parameters</option><option value="">None of the above</option></select></p></li>
<li><p>Which of the following mathematical ideas is NOT used in the above maximum likelihood estimation? <select class="webex-select"><option value="blank"></option><option value="">Identically distributed</option><option value="">Taking logs</option><option value="">By independence</option><option value="answer">The parameter θ depends on i</option><option value="">Substituting for the probability function</option><option value="">None of the above</option></select></p></li>
<li><p>Which of the following terms is used to refer to the fixed parameter Φ? <select class="webex-select"><option value="blank"></option><option value="">Independent</option><option value="">Canonical</option><option value="answer">Nuisance</option><option value="">Normally distributed</option><option value="">Annoyance</option><option value="">None of the above</option></select></p></li>
<li><p>Which of the following is NOT a good property of a parameter estimator? <select class="webex-select"><option value="blank"></option><option value="">Has expectation equal to the true value</option><option value="">Variance decreases as sample size increases</option><option value="">Unbiased</option><option value="answer">Has fixed variance for all sample sizes</option><option value="">Small variance</option><option value="">None of the above</option></select></p></li>
<li><p>Which of the following does NOT influence the variance of the estimator of θ? <select class="webex-select"><option value="blank"></option><option value="">The sample size</option><option value="answer">c(y,Φ)</option><option value="">b(θ)</option><option value="">Φ</option><option value="">The true parameter value</option><option value="">None of the above</option></select></p></li>
</ol>
</div>
</div>
</section>
<section id="sec-mlegeneral" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sec-mlegeneral"><span class="header-section-number">4.2</span> The general case</h2>
<section id="mle-estimation" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="mle-estimation"><span class="header-section-number">4.2.1</span> MLE Estimation</h3>
<p>Suppose that now the <span class="math inline">\(n\)</span> independent observations <span class="math inline">\(\mathbf{y} = \{y_i,\ i=1,\dots,n\}\)</span> are not identically distributed. They are, however, sampled from the same exponential family density but with differing parameters, that is <span class="math display">\[
f(y_i; \theta_i,\phi) = \exp \left\{ \frac{y_i\theta_i  - b(\theta_i)}{\phi} + c(y_i, \phi) \right\},
\]</span> for <span class="math inline">\(i=1,\dots,n.\)</span> In this case, the canonical parameter does depend on <span class="math inline">\(i\)</span> – but we assume that the scale parameter <span class="math inline">\(\phi\)</span> does not – and let <span class="math inline">\(\boldsymbol{\theta} = \{\theta_i,\ i=1,\dots,n\}\)</span>.</p>
<p>In most applications, we are not interested in estimation of <span class="math inline">\(\boldsymbol{\theta}\)</span> but instead we are interested in the linear predictor parameters <span class="math inline">\(\boldsymbol{\beta} =\{\beta_1,\dots,\beta_p\}\)</span>. Note, however, that each <span class="math inline">\(\theta_i\)</span> will depend on all <span class="math inline">\(\beta_1,\dots,\beta_p\)</span>. This is most obvious for the canonical parameter case where a convenient choice of link function is obtained using <span class="math inline">\(\boldsymbol{\theta} = \eta = X\boldsymbol{\beta}\)</span>, hence <span class="math inline">\(\theta_i= \mathbf{x}_i^T \boldsymbol{\beta} =\sum_{j=1}^p x_{ij}\beta_{j}\)</span> and each <span class="math inline">\(\theta_i\)</span> clearly depends on all <span class="math inline">\(\beta_1,\dots,\beta_p\)</span>.</p>
<p>The principle of maximum likelihood will be used to estimate the model parameters <span class="math inline">\(\boldsymbol{\beta}\)</span>. Using the independence of <span class="math inline">\(\mathbf{y} = \{y_i,\ i=1,\dots,n\}\)</span>, given the parameters <span class="math inline">\(\boldsymbol{\beta}\)</span>, the likelihood function is: <span id="eq-likelihoodgeneral"><span class="math display">\[
L(\boldsymbol{\beta}; \mathbf{y}, \phi)
= f(\mathbf{y}; X, \boldsymbol{\beta},\phi)
= \prod_{i=1}^n f(y_i; \mathbf{x}_i, \boldsymbol{\beta}, \phi)
\tag{4.11}\]</span></span> and the log-likelihood by <span id="eq-loglikelihoodgeneral"><span class="math display">\[
l (\boldsymbol{\beta}; \mathbf{y}, \phi)
= \log L(\boldsymbol{\beta}; \mathbf{y}, \phi)
= \sum_{i=1}^n \log f(y_i;
\mathbf{x}_i,
\boldsymbol{\beta}, \phi).
\tag{4.12}\]</span></span> Then we wish to find the value of <span class="math inline">\(\boldsymbol{\beta}\)</span> which maximizes the log-likelihood function, <span class="math display">\[
\hat{\boldsymbol{\beta}} =
\max_{\boldsymbol{\beta}}
l (\boldsymbol{\beta}; \mathbf{y}, \phi).
\]</span> For generalised linear models there is usually no closed-form expression for the MLE <span class="math inline">\(\hat{\boldsymbol{\beta}}.\)</span> Instead, an iterative approach based on Newton’s Method is often used.</p>
<p>For the normal linear regression model, however, that is where the exponential family is Gaussian and the link function <span class="math inline">\(g(\mu)\)</span> is the identity function, we have the familiar closed-form expression <span id="eq-linearregressionmle"><span class="math display">\[
\hat{\boldsymbol{\beta}} = \left(X^T X\right)^{-1} X^T \mathbf{y}.
\tag{4.13}\]</span></span></p>
</section>
<section id="sec-score" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="sec-score"><span class="header-section-number">4.2.2</span> The score function and Fisher information</h3>
<p>We define the <em>score function</em>: <span id="eq-u"><span class="math display">\[
U(\boldsymbol{\beta}) = \frac{\partial l(\boldsymbol{\beta}; \mathbf{y},\phi)} {\partial \boldsymbol{\beta}},
\tag{4.14}\]</span></span> which is a <span class="math inline">\(p \times 1\)</span> vector. We define the <em>observed Fisher information</em>: <span id="eq-i"><span class="math display">\[
{\cal I}(\boldsymbol{\beta}) = - \frac{\partial U(\boldsymbol{\beta})} {\partial \boldsymbol{\beta}^T}
          = -\frac{\partial^2 l(\boldsymbol{\beta}; \mathbf{y},\phi)} {\partial \boldsymbol{\beta} \, \partial \boldsymbol{\beta}^T},
\tag{4.15}\]</span></span> which is a <span class="math inline">\(p \times p\)</span> matrix whose <span class="math inline">\((j,k)\)</span>th element is: <span class="math inline">\(-\frac{\partial^2 l(\boldsymbol{\beta}; \mathbf{y},\phi)} {\partial \beta_j\partial \beta_k}\)</span>. We also define the <em>expected Fisher information</em>: <span id="eq-j"><span class="math display">\[
{\cal J}(\boldsymbol{\beta}) = \mbox{E}\left[ -\frac{\partial^2 l(\boldsymbol{\beta}; \mathbf{y},\phi)} {\partial \boldsymbol{\beta} \, \partial \boldsymbol{\beta}^T} \right],
\tag{4.16}\]</span></span> which is also a <span class="math inline">\(p \times p\)</span> matrix.</p>
<p>Newton’s Method then involves choosing an initial value for the parameter vector, <span class="math inline">\(\hat{\boldsymbol{\beta}}_0\)</span> say, and then repeatedly updating, until convergence, the value using <span class="math inline">\(\hat{\boldsymbol{\beta}}_t = \hat{\boldsymbol{\beta}}_{t-1} - {\cal I}^{-1}(\hat{\boldsymbol{\beta}}_{t-1})\; U(\hat{\boldsymbol{\beta}}_{t-1})\)</span>. A related method, called Fisher Scoring, replaces <span class="math inline">\({\cal I}\)</span> in the iterative step by <span class="math inline">\({\cal J}\)</span> – calculating the expected Fisher information is more work but does lead to better numerical properties.</p>
<div id="prp-uj" class="proposition theorem proposition">
<p><span class="theorem-title"><strong>Proposition 4.1 </strong></span>With definitions <a href="#eq-u">Equation&nbsp;<span>4.14</span></a>, <a href="#eq-i">Equation&nbsp;<span>4.15</span></a>, <a href="#eq-j">Equation&nbsp;<span>4.16</span></a> above,</p>
<ul>
<li><span class="math inline">\(\mbox{E}\left[U(\boldsymbol{\beta})\right] = 0\)</span>,</li>
<li><span class="math inline">\({\cal J}(\boldsymbol{\beta}) = \mbox{E}\left[U(\boldsymbol{\beta}) U^T(\boldsymbol{\beta})\right]\)</span>.</li>
</ul>
</div>
<p><strong>Proof</strong> We give the proof for continuous random variables. For the discrete case, replace integration by sums – see Exercises.</p>
<p>To start the proof, notice that we can re-write the joint density of the data given the parameters as <span class="math display">\[
f(\mathbf{y}; X, \boldsymbol{\beta},\phi) = L(\boldsymbol{\beta}; \mathbf{y}, \phi) =\exp\left\{ l(\boldsymbol{\beta}; \mathbf{y},\phi)\right\}
\]</span> and then <span class="math display">\[
1 = \int f(\mathbf{y}; X \boldsymbol{\beta},\phi) d\mathbf{y}
  = \int \exp\{ l(\boldsymbol{\beta}; \mathbf{y},\phi)\} d\mathbf{y},
\]</span> where <span class="math inline">\(d\mathbf{y}=dy_1\cdots dy_n\)</span>. Differentiating this with respect to <span class="math inline">\(\boldsymbol{\beta}=(\beta_1,\dots,\beta_p)^T\)</span> gives: <span class="math display">\[\begin{align*}
0 &amp; = \int \frac{\partial l(\boldsymbol{\beta}; \mathbf{y},\phi)} {\partial \boldsymbol{\beta}}
      \exp\{ l(\boldsymbol{\beta}; \mathbf{y},\phi)\} d\mathbf{y}  \\
&amp; = \int U(\boldsymbol{\beta}) f(\mathbf{y}; X, \boldsymbol{\beta},\phi) d\mathbf{y}  \tag{$\star$} \\
&amp;= \mbox{E}\left[U(\boldsymbol{\beta})\right].
\end{align*}\]</span> Proving the first part.</p>
<p>Next, differentiating <span class="math inline">\((\star)\)</span> by parts with respect to &nbsp;<span class="math inline">\(\boldsymbol{\beta}^T\)</span>, <span class="math display">\[\begin{align*}
0 &amp; = \int \frac{\partial U(\boldsymbol{\beta})} {\partial \boldsymbol{\beta}^T}
      f(\mathbf{y}; X, \boldsymbol{\beta},\phi)  + \frac{\partial l(\boldsymbol{\beta}; \mathbf{y},\phi)}
      {\partial \boldsymbol{\beta}} \frac{\partial l(\boldsymbol{\beta}; \mathbf{y},\phi)}
      {\partial \boldsymbol{\beta}^T} f(\mathbf{y}; X, \boldsymbol{\beta},\phi) d\mathbf{y} \\[2mm]
&amp; = \int - {\cal I}(\boldsymbol{\beta}) f(\mathbf{y}; X, \boldsymbol{\beta},\phi) d\mathbf{y}
    + \int U(\boldsymbol{\beta}) U^T(\boldsymbol{\beta}) f(\mathbf{y}; X, \boldsymbol{\beta},\phi) d\mathbf{y} \\[2mm]
&amp; = - {\cal J}(\boldsymbol{\beta}) + \mbox{E}\left[U(\boldsymbol{\beta}) U^T(\boldsymbol{\beta})\right].
\end{align*}\]</span> proving the second part.</p>
<div id="prp-asymptotic" class="proposition theorem proposition">
<p><span class="theorem-title"><strong>Proposition 4.2 </strong></span>Under some regularity conditions, the MLE <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> of <span class="math inline">\(\boldsymbol{\beta}\)</span> has the following asymptotic properties:</p>
<ul>
<li><span class="math inline">\(\mbox{E}(\hat{\boldsymbol{\beta}}) = \boldsymbol{\beta}\)</span>; i.e.&nbsp;<span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> is unbiased for <span class="math inline">\(\boldsymbol{\beta}\)</span>.</li>
<li><span class="math inline">\(\mbox{Var}(\hat{\boldsymbol{\beta}}) = {\cal J}^{-1}(\boldsymbol{\beta})\)</span>.</li>
<li><span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> follows a <span class="math inline">\(p\)</span>-dimensional Normal distribution.</li>
</ul>
<p>Combining these three statements we have that asymptotically <span id="eq-betahatdistribution"><span class="math display">\[
\hat{\boldsymbol{\beta}} \sim N_p (\boldsymbol{\beta}, {\cal J}^{-1}(\boldsymbol{\beta})).
\tag{4.17}\]</span></span></p>
</div>
<p><strong>Proof:</strong> Omitted. Similar to the proof using Taylor’s theorem in <a href="#sec-mleiid"><span>Section&nbsp;4.1</span></a>.</p>
<p>From <a href="#eq-betahatdistribution">Equation&nbsp;<span>4.17</span></a>, variances <span class="math inline">\(\text{Var}(\hat{\beta}_{k})\)</span>, standard errors <span class="math inline">\(\text{se}(\hat{\beta}_{k})\)</span> and correlations between parameter estimates <span class="math inline">\(\text{Corr}(\hat{\beta}_{k},\hat{\beta}_{h})\)</span> can be estimated.</p>
</section>
<section id="sec-mlesaturated" class="level3" data-number="4.2.3">
<h3 data-number="4.2.3" class="anchored" data-anchor-id="sec-mlesaturated"><span class="header-section-number">4.2.3</span> The saturated case</h3>
<p>Again we assume the observations <span class="math inline">\(y_i,\ i=1,\dots,n\)</span> are independent but now we assume that <span class="math inline">\(y_i\)</span> is sampled from an exponential family probability function with canonical parameter <span class="math inline">\(\theta_i\)</span>, <span class="math display">\[
f(y_i; \theta_i,\phi) = \exp \left\{ \frac{y_i\theta_i  - b(\theta_i)}{\phi} + c(y_i, \phi) \right\},
\]</span> for <span class="math inline">\(i=1,\dots,n.\)</span> We can form the log-likelihood in the usual way to give <span class="math display">\[
l (\boldsymbol{\theta}; \mathbf{y}, \phi) = \sum_{i=1}^n \log f(y_i; \theta_i, \phi)
= \sum_{i=1}^n \left[\frac{y_i\theta_i  - b(\theta_i)}{\phi} + c(y_i, \phi)\right]
\]</span> and so we find the the MLE of <span class="math inline">\(\boldsymbol{\theta}\)</span> using <span class="math display">\[
\hat \theta_i = (b')^{-1}(y_i),
\quad i=1,\dots,n.
\]</span> Note that each parameter is only a function of the corresponding observation.</p>
<p>Further, from <a href="3_GLM-Theory.html#prp-moments">Proposition&nbsp;<span>3.1</span></a>, <span class="math inline">\(\mbox{E}[Y_i] = \mu_i =b'(\theta_i)\)</span> and if we again let <span class="math inline">\(\hat\mu_i\)</span> denote the MLE of <span class="math inline">\(\mu_i\)</span>, then <span class="math inline">\(\hat\mu_i = b'(\hat{\theta_i})\)</span>, hence we have <span class="math inline">\(\hat\mu_i = y_i\)</span>. Thus we see that, under the saturated model, the mean of the distribution of <span class="math inline">\(y_i\)</span> is estimated to be equal to <span class="math inline">\(y_i\)</span> itself. That is, the data are fitted exactly by the model. Of course this model is quite useless for explanation or prediction, since it misinterprets random variation as systematic variation. Nevertheless, the saturated model is useful as a benchmark for comparing models, as we will see later.</p>
<p>It is worth noting that the same situation can occur even when modelling in terms of the regression parameters <span class="math inline">\(\beta_j,\ j=1,\dots,p\)</span>. When <span class="math inline">\(p\geq n\)</span>, and if the covariates are linearly independent, each <span class="math inline">\(\theta_i\)</span> can take on any value independently of the others and so estimating the <span class="math inline">\(\beta_j\)</span>’s is equivalent to estimating the <span class="math inline">\(\theta_i\)</span>’s. That is we are also considering the <em>saturated</em> or <em>full</em> model. This highlights the danger of putting too many covariates into the model. There is a big literature on how to deal with more parameters then data using techniques of <em>regularised regression</em>.</p>
</section>
</section>
<section id="focus-on-general-maximum-likelihood-quiz" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="focus-on-general-maximum-likelihood-quiz">Focus on general maximum likelihood quiz</h2>
<p>Test your knowledge recall and application to reinforce basic ideas and prepare for similar concepts later in the Chapter</p>
<div class="webex-box">
<div class="webex-check">
<ol type="1">
<li><p>Which of the following statements best describes the purpose of maximum likelihood estimation? <select class="webex-select"><option value="blank"></option><option value="">To find the true values of model parameters</option><option value="answer">To find good values of unknown model parameters</option><option value="">To calculate the mean of a distribution</option><option value="">To summarise a data set</option><option value="">To estimate probabilities of unknown events</option><option value="">None of the above</option></select></p></li>
<li><p>Which of the following mathematical ideas is NOT used in the general case of maximum likelihood estimation? <select class="webex-select"><option value="blank"></option><option value="">Usually no closed-form expression</option><option value="answer">The parameter θ does not depends on i</option><option value="">Using the independence</option><option value="">Not identically distributed</option><option value="">The log-likelihood</option><option value="">None of the above</option></select></p></li>
<li><p>Which of the following terms is NOT used in maximum likelihood theory? <select class="webex-select"><option value="blank"></option><option value="">Score function</option><option value="">The log-likelihood function</option><option value="">Fisher information</option><option value="answer">The moment generating function</option><option value="">The likelihood function</option><option value="">None of the above</option></select></p></li>
<li><p>Which of the following is a true statement about the saturated case? <select class="webex-select"><option value="blank"></option><option value="">Has fewer parameters than data observations</option><option value="">The values of θ will be exactly the same as the values of β</option><option value="">It should never be considered</option><option value="answer">The model fits the data exactly</option><option value="">The parameters θ and unrelated to the values of β</option><option value="">None of the above</option></select></p></li>
<li><p>Which of the following is NOT a true statement about the asymptotic properties of the maximum likelihood estimator of β? <select class="webex-select"><option value="blank"></option><option value="answer">Will always be equal to the true value.</option><option value="">Follows a normal distribution</option><option value="">Is unbiased</option><option value="">The variance can be found form the expected Fisher information</option><option value="">The asymptotic properties are when n tend to infinity</option><option value="">None of the above</option></select></p></li>
</ol>
</div>
</div>
</section>
<section id="sec-deviance" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="sec-deviance"><span class="header-section-number">4.3</span> Model deviance</h2>
<p>The <em>deviance</em> is a quantity we use to assess the fit of a model to the data. Let <span class="math inline">\(M\)</span> be a model of interest with fitted parameters <span class="math inline">\(\hat{\boldsymbol\theta}\)</span> and corresponding fitted values <span class="math inline">\(\hat{\boldsymbol\mu}\)</span>. Also consider the saturated model with fitted parameters <span class="math inline">\(\tilde{\boldsymbol\theta}\)</span> and fitted values <span class="math inline">\(\tilde{\boldsymbol\mu}\)</span>.</p>
<p>The <em>deviance</em> of model <span class="math inline">\(M\)</span> is defined as twice the difference between the log-likelihood of the saturated model, <span class="math inline">\(l(\tilde{\boldsymbol\theta};\mathbf{y},\phi)\)</span>, and the log-likelihood of model <span class="math inline">\(M\)</span>, <span class="math inline">\(l(\hat{\boldsymbol\theta}; \mathbf{y},\phi)\)</span>, multiplied by <span class="math inline">\(\phi\)</span>, <span class="math display">\[\begin{eqnarray}
D
&amp; = &amp; 2 \phi \left\{ l(\tilde{\boldsymbol\theta};\mathbf{y},\phi) - l(\hat{\boldsymbol\theta}; \mathbf{y},\phi) \right\} \label{eq:deviance}\\[4mm]
&amp; = &amp;  \left\{ \begin{array}{ll}
    \sum_{i=1}^n  (y_i - \hat\mu_i)^2
   = \mbox{Residual sum of squares} &amp;  \mbox{ Normal} \\[3mm]
   2 \sum_{i=1}^n \left\{ y_i \log \left( \frac{y_i}{\hat\mu_i} \right)
   + (m_i - y_i) \log \left( \frac{m_i - y_i}{m_i - \hat\mu_i} \right) \right\}
   &amp;  \mbox{ Binomial} \\[3mm]
   2 \sum_{i=1}^n \left\{ y_i \log \left( \frac{y_i}{\hat\mu_i} \right)
   - y_i + \hat\mu_i \right\} &amp;  \mbox{ Poisson} \\ \end{array} \right. \notag
\end{eqnarray}\]</span></p>
<p>Note that Dobson, and others, call <span class="math inline">\(D^*= D/\phi=2 \{ l(\tilde{\theta};y,\phi) - l(\hat{\theta}; y,\phi)\}\)</span> the <em>scaled</em> deviance.</p>
<p>We now consider two situations:</p>
<p><strong>Scale parameter <span class="math inline">\(\phi\)</span> known.</strong> For some data-types (e.g.&nbsp;Poisson, Binomial), we know <span class="math inline">\(\phi=1\)</span>. Consider two nested models <span class="math inline">\(M_1\)</span> and <span class="math inline">\(M_2\)</span> with <span class="math inline">\(r_1\)</span> and <span class="math inline">\(r_2\)</span> parameters respectively where the parameters in <span class="math inline">\(M_1\)</span> are a subset of those in <span class="math inline">\(M_2\)</span> and hence <span class="math inline">\(r_1 &lt; r_2\)</span>. Further, let <span class="math inline">\(D_1\)</span> and <span class="math inline">\(D_2\)</span> be the deviances of model <span class="math inline">\(M_1\)</span> and <span class="math inline">\(M_2\)</span> respectively.</p>
<p>Then, asymptotically,</p>
<ul>
<li><p>the log likelihood-ratio statistic <span class="math inline">\(D_1 - D_2 \sim \chi^2_{r_2 - r_1}\)</span> can be used to test the importance of the extra parameters in <span class="math inline">\(M_2\)</span> not included in <span class="math inline">\(M_1;\)</span></p></li>
<li><p>a goodness-of-fit test for <span class="math inline">\(M_2\)</span> can be done based on <span class="math inline">\(D_2 \sim \chi^2_{n - r_2}\)</span>.</p></li>
</ul>
<p>The quality of the approximations involved depends on there being a large amount of <em>information</em>, for example, large counts for Binomial and Poisson data, or a large sample size for Normal data.</p>
<p><strong>Scale parameter <span class="math inline">\(\phi\)</span> unknown.</strong> For some data-types (e.g.&nbsp;Normal, Gamma), <span class="math inline">\(\phi\)</span> is not known (typically <span class="math inline">\(\phi = \sigma^2\)</span>). We must find a model <span class="math inline">\(M_3\)</span> <em>big</em> enough to be believed, then estimate <span class="math inline">\(\phi\)</span> by the residual mean square: <span id="eq-phihat"><span class="math display">\[
    \hat{\phi} = \frac{D_3}{n - r_3}.
     \tag{4.18}\]</span></span> Then test <span class="math inline">\(M_1\)</span> against <span class="math inline">\(M_2\)</span> using <span id="eq-deviance-ratio"><span class="math display">\[
    \mbox{F}=\frac{(D_1 - D_2) / (r_2 - r_1)}{\hat{\phi}} = \frac{(D_1 - D_2) / (r_2 - r_1)}{D_3/(n-r_3)}
     \tag{4.19}\]</span></span> with <span id="eq-ftest"><span class="math display">\[
    \mbox{F} \sim F_{r_2 - r_1, n - r_3}.
     \tag{4.20}\]</span></span> So if the observed value of the statistic <a href="#eq-deviance-ratio">Equation&nbsp;<span>4.19</span></a> was within the upper (say 5%) tail of the <span class="math inline">\(F\)</span>-distribution <a href="#eq-ftest">Equation&nbsp;<span>4.20</span></a>, we would infer that Model <span class="math inline">\(M_2\)</span> is better than Model <span class="math inline">\(M_1\)</span>.</p>
</section>
<section id="model-residuals" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="model-residuals"><span class="header-section-number">4.4</span> Model residuals</h2>
<p>Consider a generalised linear model with observed values <span class="math inline">\(y_i, i=1,\dots,n\)</span> and fitted values <span class="math inline">\(\hat\mu_i\)</span>. Then the <em>raw</em> or <em>response</em> residuals are defined by <span class="math display">\[
e_i^\text{raw} = y_i - \hat\mu_i.
\]</span></p>
<p>More useful are the <em>standardised</em> or <em>Pearson</em> residuals defined by <span class="math display">\[
e_i^\text{std} =
e_i^\text{P} = \frac{y_i - \hat\mu_i}{\sqrt{ b''(\theta_i)}}.
\]</span> Recall from <a href="3_GLM-Theory.html#eq-exponential-moments">Equation&nbsp;<span>3.8</span></a> that <span class="math inline">\(\text{Var}(Y_i) = \phi \, b''(\theta_i)\)</span>.</p>
<p><em>Deviance residuals</em> are defined so that the sum of squared deviance residuals equals the total deviance. Thus we set <span class="math display">\[
e_i^\text{dev} = \text{sign}(y_i - \hat\mu_i) \sqrt{d_i},
\]</span> where <span class="math inline">\(d_i\)</span> is the contribution of observation <span class="math inline">\(i\)</span> to the deviance, <span class="math inline">\(D\)</span>. For example, when <span class="math inline">\(y_i\)</span> has a Poisson distribution with estimated mean <span class="math inline">\(\hat{\mu}_i\)</span>, we have <span class="math display">\[
e_i^\text{dev} = \text{sign}(y_i - \hat\mu_i) \sqrt{2\left[y_i \log\left(\frac{y_i}{\hat{\mu}_i}\right) - y_i + \hat{\mu}_i\right]}.
\]</span></p>
<p>Residuals are useful for assessing the overall fit of a model to the data, and for identifying where the model might need to be improved.</p>
</section>
<section id="fitting-generalised-linear-models-in-r" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="fitting-generalised-linear-models-in-r"><span class="header-section-number">4.5</span> Fitting generalised linear models in <strong>R</strong></h2>
<section id="glm-related-r-commands" class="level3" data-number="4.5.1">
<h3 data-number="4.5.1" class="anchored" data-anchor-id="glm-related-r-commands"><span class="header-section-number">4.5.1</span> GLM-related <strong>R</strong> commands</h3>
<p>The function used to fit a generalised linear model in <span class="math inline">\(\mathbf R\)</span> is <span class="math display">\[\texttt{glm(formula, family)}.\]</span></p>
<p>Let <span class="math inline">\(\texttt{x,y,z,a,b,c,}\)</span> <span class="math inline">\(\dots\)</span> be a set of vectors all of the same length <span class="math inline">\(n\)</span> (perhaps read in from a data file using the <span class="math inline">\(\texttt{read.table}\)</span> and <span class="math inline">\(\texttt{attach}\)</span> commands). If <span class="math inline">\(\texttt{a,b,c}\)</span> are qualitative variables, then they first need to be declared as factors by <span class="math inline">\(\texttt{a = as.factor(a)}\)</span>, etc.</p>
<p>The <span class="math inline">\(\texttt{formula}\)</span> argument of <span class="math inline">\(\texttt{glm}\)</span> specifies the required model in compact notation, e.g. <span class="math inline">\(\texttt{y} \sim \texttt{x*a}\)</span> or <span class="math inline">\(\texttt{y} \sim \texttt{x + z*a}\)</span> where <span class="math inline">\(\sim, \texttt{+,*}\)</span> have the same meaning as in <a href="2_linearmodels.html#sec-shorthand"><span>Section&nbsp;2.5</span></a>.</p>
<p>The <span class="math inline">\(\texttt{family}\)</span> argument specifies which exponential family is to be used. We shall use <span class="math inline">\(\texttt{gaussian, poisson}\)</span> and <span class="math inline">\(\texttt{binomial}\)</span>; <span class="math inline">\(\texttt{gaussian}\)</span> is the default. Other options are available; see <span class="math inline">\(\texttt{help(family)}\)</span> for further information.</p>
<p>Along with the family, a link function can be specified. The possible choices are:</p>
<ul>
<li><span class="math inline">\(\texttt{gaussian} - \texttt{"identity"}\)</span> (default)</li>
<li><span class="math inline">\(\texttt{poisson} - \texttt{"log"}\)</span> (default), <span class="math inline">\(\texttt{"sqrt"}\)</span>, <span class="math inline">\(\texttt{"identity"}\)</span></li>
<li><span class="math inline">\(\texttt{binomial} - \texttt{"logit"}\)</span> (default), <span class="math inline">\(\texttt{"probit"}\)</span>, <span class="math inline">\(\texttt{"cloglog"}\)</span>.</li>
</ul>
<p><strong>R</strong> assumes the default options unless we state otherwise. For example,</p>
<p><span class="math inline">\(\texttt{glm(y}\sim\texttt{a+b)}\)</span> # Gaussian errors, identity link<br>
<span class="math inline">\(\texttt{glm(y}\sim a+b\texttt{, poisson)}\)</span> # Poisson errors, log link<br>
<span class="math inline">\(\texttt{glm(y}\sim\texttt{a+b, poisson("sqrt"))}\)</span> # Poisson errors, sqrt link</p>
<p><strong>Note that for the binomial case</strong>, the response variable should be an <span class="math inline">\(n \times 2\)</span> matrix <span class="math inline">\(\texttt{ym}\)</span>, say, not a vector, where the first column contains the numbers of successes and the second column the numbers of failures, for example:</p>
<p><span class="math inline">\(\texttt{glm(ym}\sim\texttt{ a+b, binomial)}\)</span> # binomial errors, logit link</p>
<p>To extract information about a fitted generalised linear model, it is best to store the result of <span class="math inline">\(\texttt{glm}\)</span> as a variable and then to use the following functions:</p>
<ul>
<li>To fit a GLM and store the result in <span class="math inline">\(\texttt{y.glm}\)</span> (for example):<br>
<span class="math inline">\(\texttt{y.glm = glm(y}\sim\texttt{a*b, poisson("sqrt"))}\)</span></li>
<li>To print various pieces of information including deviance residuals, parameter estimates and standard errors, deviances, and (if specified) correlations of parameter estimates:<br>
<span class="math inline">\(\texttt{summary(y.glm, correlation=T)}\)</span></li>
<li>To print the anova table of the fitted model:<br>
<span class="math inline">\(\texttt{anova(y.glm)}\)</span></li>
<li>To print the deviance of the fitted model:<br>
<span class="math inline">\(\texttt{deviance(y.glm)}\)</span></li>
<li>To print the residual degrees of freedom of the fitted model:<br>
<span class="math inline">\(\texttt{df.residual(y.glm)}\)</span></li>
<li>To print the vector of fitted values under the fitted model:<br>
<span class="math inline">\(\texttt{fitted.values(y.glm)}\)</span></li>
<li>To print the residuals from the fitted model:<br>
<span class="math inline">\(\texttt{residuals(y.glm, type)}\)</span><br>
Note: <span class="math inline">\(\texttt{type}\)</span> should be <span class="math inline">\(\texttt{"deviance"}\)</span> (default), <span class="math inline">\(\texttt{"pearson"}\)</span>, or <span class="math inline">\(\texttt{"response"}\)</span></li>
<li>To print the parameter estimates from the fitted model:<br>
<span class="math inline">\(\texttt{coefficients(y.glm)}\)</span></li>
<li>To print the design matrix for a specified model formula: <span class="math inline">\(\texttt{model.matrix(y}\sim\texttt{a*b)}\)</span></li>
</ul>
<p>The functions <span class="math inline">\(\texttt{summary}\)</span> and <span class="math inline">\(\texttt{anova}\)</span> are the most useful for printing out information about the fitted model. The results of the other functions can be saved as variables for further computation, if desired.</p>
</section>
<section id="example-of-fitting-poisson-glm-in-r" class="level3" data-number="4.5.2">
<h3 data-number="4.5.2" class="anchored" data-anchor-id="example-of-fitting-poisson-glm-in-r"><span class="header-section-number">4.5.2</span> Example of fitting Poisson GLM in <strong>R</strong></h3>
<p>Here is a toy example of <strong>R</strong> commands for modelling a response in terms of two qualitative explanatory variables (that is <em>factors</em>). The model assumes the data are Poisson-distributed and uses the logarithmic link function.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">7</span>, <span class="dv">10</span>, <span class="dv">2</span>, <span class="dv">8</span>, <span class="dv">16</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>,<span class="at">times=</span><span class="dv">3</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,<span class="at">each=</span><span class="dv">4</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>a <span class="ot">=</span> <span class="fu">as.factor</span>(a)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">as.factor</span>(b)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>y.glm <span class="ot">=</span> <span class="fu">glm</span>(y <span class="sc">~</span> a<span class="sc">+</span>b, poisson)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(y.glm, <span class="at">correlation=</span>T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = y ~ a + b, family = poisson)

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   1.1408     0.3351   3.404 0.000663 ***
a2           -0.3054     0.3522  -0.867 0.385934    
a3            0.1466     0.3132   0.468 0.639712    
a4            0.4568     0.2932   1.558 0.119269    
b2            0.9163     0.3162   2.898 0.003761 ** 
b3            0.9445     0.3150   2.999 0.002712 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 31.725  on 11  degrees of freedom
Residual deviance: 13.150  on  6  degrees of freedom
AIC: 68.227

Number of Fisher Scoring iterations: 5

Correlation of Coefficients:
   (Intercept) a2    a3    a4    b2   
a2 -0.45                              
a3 -0.50        0.48                  
a4 -0.54        0.51  0.57            
b2 -0.67        0.00  0.00  0.00      
b3 -0.68        0.00  0.00  0.00  0.72</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(y.glm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table

Model: poisson, link: log

Response: y

Terms added sequentially (first to last)

     Df Deviance Resid. Df Resid. Dev
NULL                    11     31.725
a     3   6.2793         8     25.445
b     2  12.2947         6     13.150</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">deviance</span>(y.glm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 13.15047</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">df.residual</span>(y.glm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fitted.values</span>(y.glm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>        1         2         3         4         5         6         7         8 
 3.129412  2.305882  3.623529  4.941176  7.823529  5.764706  9.058824 12.352941 
        9        10        11        12 
 8.047059  5.929412  9.317647 12.705882 </code></pre>
</div>
</div>
</section>
</section>
<section id="focus-on-glm-fitting-in-r-quiz" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="focus-on-glm-fitting-in-r-quiz">Focus on GLM fitting in R quiz</h2>
<p>Test your knowledge recall and application to reinforce basic ideas and prepare for similar concepts later in the Chapter</p>
<div class="webex-box">
<div class="webex-check">
<ol type="1">
<li><p>Which of the following is the main R command used to fit generalised linear models? <select class="webex-select"><option value="blank"></option><option value="">family</option><option value="answer">glm</option><option value="">lm</option><option value="">fitglm</option><option value="">formula</option><option value="">None of the above</option></select></p></li>
<li><p>Which of the following is NOT an option for the model family? <select class="webex-select"><option value="blank"></option><option value="">gaussian</option><option value="">binomial</option><option value="answer">logit</option><option value="">poisson</option><option value="">Gamma</option><option value="">None of the above</option></select></p></li>
<li><p>Which of the following is NOT a link option in a GLM? <select class="webex-select"><option value="blank"></option><option value="">log</option><option value="">identity</option><option value="">probit</option><option value="answer">constant</option><option value="">logit</option><option value="">None of the above</option></select></p></li>
<li><p>Which of the following is NOT a link option with the binomial family? <select class="webex-select"><option value="blank"></option><option value="">cauchit</option><option value="">log</option><option value="answer">inverse</option><option value="">logit</option><option value="">cloglog</option><option value="">None of the above</option></select></p></li>
<li><p>Which of the following is NOT a n R command used to check model fit? <select class="webex-select"><option value="blank"></option><option value="">anova</option><option value="">residuals</option><option value="">summary</option><option value="">deviance</option><option value="answer">glm</option><option value="">None of the above</option></select></p></li>
</ol>
</div>
</div>
</section>
<section id="exercises" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="exercises"><span class="header-section-number">4.6</span> Exercises</h2>
<div class="webex-box">
<p>4.1 Use <a href="#eq-exponentialfamilybary2">Equation&nbsp;<span>4.4</span></a> to obtain estimation equations for the natural parameter <span class="math inline">\(\theta\)</span>, based on a sample <span class="math inline">\(\mathbf{y}=\{y_1,\dots, y_n\}\)</span>, for each of the following situations:</p>
<ol type="a">
<li>the binomial, <span class="math inline">\(Y\sim\mbox{Bin}(m,p)\)</span>,</li>
<li>the geometric, <span class="math inline">\(Y\sim\mbox{Ge}(p)\)</span>,</li>
<li>the exponential, <span class="math inline">\(Y\sim\mbox{Exp}(\lambda)\)</span>.</li>
</ol>
Assuming that <span class="math inline">\(n\)</span> is very large, use <a href="#eq-ehattheta">Equation&nbsp;<span>4.9</span></a> to comment on possible bias of the estimator for large samples. What is the corresponding variance of the estimator?
<div class="webex-solution">
<button>
Click here to see hints.
</button>
<p>For each situation equate the theoretical expectation, in terms of the derivative of b, to the sample mean – that is start from <a href="#eq-exponentialfamilybary">Equation&nbsp;<span>4.3</span></a> and solve. For bias and variance you should consider the asymptotic results.</p>
</div>
4.2 For a sample of size <span class="math inline">\(n\)</span> from the normal distribution, <span class="math inline">\(Y\sim N(\mu, \sigma^2),\)</span> how do the results produced using <a href="#eq-ehattheta">Equation&nbsp;<span>4.9</span></a> and <a href="#eq-varhattheta">Equation&nbsp;<span>4.10</span></a> compare with the familiar results <span class="math inline">\(\hat\mu =\bar Y\)</span>, <span class="math inline">\(\text{E}[\hat\mu]=\mu\)</span>, and <span class="math inline">\(\text{Var}[\hat\mu] =\sigma^2/n?\)</span>
<div class="webex-solution">
<button>
Click here to see hints.
</button>
<p>Identify, <span class="math inline">\(\theta\)</span>, <span class="math inline">\(\phi\)</span> and <span class="math inline">\(b''(\theta)\)</span> then substitute into the equations.</p>
</div>
4.3 For the normal linear regression model, <span class="math inline">\(\mathbf{Y}=X\boldsymbol{\beta}+\boldsymbol{\epsilon}\)</span> where <span class="math inline">\(\boldsymbol{\epsilon}\sim N_n(0,\sigma^2 I_n)\)</span> use the principle of maximum likelihood to show that the MLE has the closed form given in <a href="#eq-linearregressionmle">Equation&nbsp;<span>4.13</span></a>.
<div class="webex-solution">
<button>
Click here to see hints.
</button>
<p>Apply the rules for matrix differentiation of a quadratic form. If needed, refer to <em>Appendix C</em> in the <em>Basic Pre-requisite Material folder</em> in <em>Minerva</em>.</p>
</div>
4.4 Check that you can derive the formulas given for deviance of normal, binomial, and Poisson models at the start of <a href="#sec-deviance"><span>Section&nbsp;4.3</span></a>.
<div class="webex-solution">
<button>
Click here to see hints.
</button>
<p>Form the likelihoods of the saturated model, recalling that the fitted values are exactly equal to the observed <span class="math inline">\(y\)</span> values, and substitute them into the general deviance equation. Then, simplify.</p>
</div>
4.5 How do the deviance tests defined in <a href="#sec-deviance"><span>Section&nbsp;4.3</span></a> related to the tests used to find the best fit model for the birthweight example in <a href="2_linearmodels.html#sec-essentialsoverview"><span>Section&nbsp;2.1</span></a>?
<div class="webex-solution">
<button>
Click here to see hints.
</button>
<p>Start by comparing the notation. Then, replace the <em>R</em> and <em>r</em> in the F-statistic with <em>D</em> and adjust the notation for degrees of freedom. You should then get very expressions. The only difference being from which model <span class="math inline">\(\sigma^2\)</span> is estimated.</p>
</div>
<p>4.6 Consider a clinical trial into the effectiveness of Amoxicillin (a widely used antibiotic) against bacterial chest infections in children. A sample of 200 children with chest infections were randomly assigned to one of five groups with Amoxicillin dose levels of 20-100 mg/kg per day. Four weeks later it was recorded whether the child had required a re-treatment with a further dose of antibiotic, or not, with results summarised in <a href="#tbl-antibiotic">Table&nbsp;<span>4.1</span></a></p>
<div id="tbl-antibiotic" class="anchored">
<table class="table">
<caption>Table&nbsp;4.1: Effectiveness of Amoxicillin against bacterial chest infections in children</caption>
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;">20mg</th>
<th style="text-align: center;">40mg</th>
<th style="text-align: center;">60mg</th>
<th style="text-align: center;">80mg</th>
<th style="text-align: center;">100mg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Group size</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">22</td>
</tr>
<tr class="even">
<td>Re-treatment</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">3</td>
</tr>
</tbody>
</table>
</div>
First fit a normal linear model and then fit a generalised linear model assuming binomial errors and a logistic link. Superimpose both of fitted model onto a scatter plot of the data. Which do you think is the better model? Justify you answer.
<div class="webex-solution">
<button>
Click here to see hints.
</button>
<p>The linear model part would be straightforward, look at earlier examples if not. For the glm case, check the R code block for <a href="1_intro.html#fig-beetle-fitted-2">Figure&nbsp;<span>1.1 (b)</span></a>. Simply compare the fit by eye.</p>
</div>
</div>
<p><br>
</p>
<!-- ::: {.callout-note appearance="default"} -->
<!-- [Exercise 4 Solutions can be found here.](https://richardpmann.com/MATH3823/Solutions_4.html) -->
<!-- ::: -->


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Using the result that the MLE of any function of a parameter is given by the same function applied to the MLE of the parameter.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  var t = document.getElementsByClassName("webex-total_correct");
  for (var i = 0; i < t.length; i++) {
    p = t[i].parentElement;
    var correct = p.getElementsByClassName("webex-correct").length;
    var solvemes = p.getElementsByClassName("webex-solveme").length;
    var radiogroups = p.getElementsByClassName("webex-radiogroup").length;
    var selects = p.getElementsByClassName("webex-select").length;

    t[i].innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");

  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* check answers */
check_func = function() {
  console.log("webex: check answers");

  var cl = this.parentElement.classList;
  if (cl.contains('unchecked')) {
    cl.remove("unchecked");
    this.innerHTML = "Hide Answers";
  } else {
    cl.add("unchecked");
    this.innerHTML = "Show Answers";
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");

  var cl = this.classList

  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;

  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }

  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

window.onload = function() {
  console.log("webex onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  var check_sections = document.getElementsByClassName("webex-check");
  console.log("check:", check_sections.length);
  for (var i = 0; i < check_sections.length; i++) {
    check_sections[i].classList.add("unchecked");

    let btn = document.createElement("button");
    btn.innerHTML = "Show Answers";
    btn.classList.add("webex-check-button");
    btn.onclick = check_func;
    check_sections[i].appendChild(btn);

    let spn = document.createElement("span");
    spn.classList.add("webex-total_correct");
    check_sections[i].appendChild(spn);
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;

    solveme[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }

  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
    selects[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  update_total_correct();
}

</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./3_GLM-Theory.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">GLM Theory</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./5_logisticmodel.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Modelling Proportions</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>